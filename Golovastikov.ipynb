{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efc0535",
   "metadata": {},
   "source": [
    "**Установка библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72ff7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e326e7bf",
   "metadata": {},
   "source": [
    "**Импорт библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84101be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Machcreator\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e31195",
   "metadata": {},
   "source": [
    "**Загрузка датасета**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59feee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('rusentitweet_full.csv')  # Замени на реальное имя файла\n",
    "texts = df['text'].astype(str).tolist()  # Колонка с текстами твитов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf937a1",
   "metadata": {},
   "source": [
    "**Объединяем все тексты для character-level (или token-level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ee270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = '\\n'.join(texts).lower()  # Нижний регистр для простоты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9412f",
   "metadata": {},
   "source": [
    "**Character-level подготовка**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93424e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(full_text)))\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "max_len = 60  # Длина последовательности\n",
    "step = 10\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(full_text) - max_len, step):\n",
    "    sequences.append(full_text[i: i + max_len])\n",
    "    next_chars.append(full_text[i + max_len])\n",
    "\n",
    "X = np.zeros((len(sequences), max_len, vocab_size), dtype=bool)\n",
    "y = np.zeros((len(sequences), vocab_size), dtype=bool)\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    for t, char in enumerate(seq):\n",
    "        X[i, t, char_to_ix[char]] = 1\n",
    "    y[i, char_to_ix[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2abe20",
   "metadata": {},
   "source": [
    "**Модель LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986b53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\Machcreator\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "632/632 [==============================] - 314s 491ms/step - loss: 3.7761\n",
      "Epoch 2/30\n",
      "632/632 [==============================] - 319s 504ms/step - loss: 3.0253\n",
      "Epoch 3/30\n",
      "632/632 [==============================] - 307s 486ms/step - loss: 2.7973\n",
      "Epoch 4/30\n",
      "632/632 [==============================] - 316s 500ms/step - loss: 2.7132\n",
      "Epoch 5/30\n",
      "632/632 [==============================] - 311s 492ms/step - loss: 2.6594\n",
      "Epoch 6/30\n",
      "632/632 [==============================] - 308s 487ms/step - loss: 2.6124\n",
      "Epoch 7/30\n",
      "632/632 [==============================] - 314s 497ms/step - loss: 2.5739\n",
      "Epoch 8/30\n",
      "632/632 [==============================] - 312s 494ms/step - loss: 2.5336\n",
      "Epoch 9/30\n",
      "632/632 [==============================] - 304s 482ms/step - loss: 2.4982\n",
      "Epoch 10/30\n",
      "632/632 [==============================] - 305s 483ms/step - loss: 2.4681\n",
      "Epoch 11/30\n",
      "632/632 [==============================] - 309s 488ms/step - loss: 2.4369\n",
      "Epoch 12/30\n",
      "632/632 [==============================] - 308s 488ms/step - loss: 2.4082\n",
      "Epoch 13/30\n",
      "632/632 [==============================] - 292s 461ms/step - loss: 2.3834\n",
      "Epoch 14/30\n",
      "632/632 [==============================] - 568s 900ms/step - loss: 2.3519\n",
      "Epoch 15/30\n",
      "632/632 [==============================] - 288s 455ms/step - loss: 2.3315\n",
      "Epoch 16/30\n",
      "632/632 [==============================] - 288s 456ms/step - loss: 2.3118\n",
      "Epoch 17/30\n",
      "632/632 [==============================] - 274s 433ms/step - loss: 2.2871\n",
      "Epoch 18/30\n",
      "632/632 [==============================] - 290s 459ms/step - loss: 2.3093\n",
      "Epoch 19/30\n",
      "632/632 [==============================] - 287s 454ms/step - loss: 2.2818\n",
      "Epoch 20/30\n",
      "632/632 [==============================] - 298s 472ms/step - loss: 2.2157\n",
      "Epoch 21/30\n",
      "632/632 [==============================] - 307s 486ms/step - loss: 2.1931\n",
      "Epoch 22/30\n",
      "632/632 [==============================] - 303s 479ms/step - loss: 2.1733\n",
      "Epoch 23/30\n",
      "632/632 [==============================] - 301s 476ms/step - loss: 2.1840\n",
      "Epoch 24/30\n",
      "632/632 [==============================] - 298s 471ms/step - loss: 2.1478\n",
      "Epoch 25/30\n",
      "632/632 [==============================] - 296s 468ms/step - loss: 2.1183\n",
      "Epoch 26/30\n",
      "632/632 [==============================] - 306s 484ms/step - loss: 2.0900\n",
      "Epoch 27/30\n",
      "632/632 [==============================] - 314s 498ms/step - loss: 2.0677\n",
      "Epoch 28/30\n",
      "632/632 [==============================] - 316s 500ms/step - loss: 2.0467\n",
      "Epoch 29/30\n",
      "632/632 [==============================] - 309s 488ms/step - loss: 2.0242\n",
      "Epoch 30/30\n",
      "632/632 [==============================] - 315s 498ms/step - loss: 2.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2513dda5e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(max_len, vocab_size), return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X, y, batch_size=128, epochs=30)  # Больше эпох для лучшего результата"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f97ca",
   "metadata": {},
   "source": [
    "**Генерация поста**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca6bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_post(seed_text, length=200):\n",
    "    generated = seed_text\n",
    "    seed_text = seed_text.lower()\n",
    "    for _ in range(length):\n",
    "        x = np.zeros((1, max_len, vocab_size))\n",
    "        for t, char in enumerate(seed_text):\n",
    "            if t < max_len:\n",
    "                x[0, t, char_to_ix.get(char, 0)] = 1\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_ix = np.argmax(preds)\n",
    "        next_char = ix_to_char[next_ix]\n",
    "        generated += next_char\n",
    "        seed_text = seed_text[1:] + next_char\n",
    "    return generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
